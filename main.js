// Hlavn√≠ aplikaƒçn√≠ logika - My AI Chat - Verze s proxy
// Verze: 1.4 - 2024-01-XX - Podpora GPT-4.1 Nano

const APP_VERSION = "1.4";

// Glob√°ln√≠ promƒõnn√©
let messages = [];
let rateLimitCounter = 0;
let rateLimitTimer = null;
let knowledgeBase = ""; // Ulo≈æen√° znalostn√≠ b√°ze
let agentThreadId = null; // Pro Agent API

// Naƒç√≠st znalostn√≠ b√°zi
async function loadKnowledgeBase() {
    if (!CONFIG.KNOWLEDGE_BASE.ENABLED) {
        console.log('üìö Knowledge base is disabled');
        return;
    }
    
    console.log('üìö Loading knowledge base...');
    let loadedFiles = 0;
    let allKnowledge = "";
    
    for (const file of CONFIG.KNOWLEDGE_BASE.FILES) {
        try {
            const filename = `${CONFIG.KNOWLEDGE_BASE.FILE_PREFIX}${file.name}.txt`;
            const response = await fetch(filename);
            
            if (response.ok) {
                const content = await response.text();
                if (content.trim()) {
                    allKnowledge += `\n\n=== ${file.description.toUpperCase()} ===\n${content}`;
                    loadedFiles++;
                    console.log(`‚úÖ Loaded: ${filename}`);
                }
            } else {
                console.warn(`‚ö†Ô∏è Could not load: ${filename}`);
            }
        } catch (error) {
            console.warn(`‚ö†Ô∏è Error loading ${file.name}:`, error);
        }
    }
    
    if (loadedFiles > 0) {
        knowledgeBase = CONFIG.KNOWLEDGE_BASE.CONTEXT_TEMPLATE.replace('{knowledge}', allKnowledge);
        console.log(`‚úÖ Knowledge base ready (${loadedFiles} files loaded)`);
        
        // Vypoƒç√≠tat velikost knowledge base v tokenech (p≈ôibli≈ænƒõ)
        const approxTokens = Math.ceil(knowledgeBase.length / 4);
        console.log(`üìä Knowledge base size: ~${approxTokens} tokens`);
        
        // Upozornƒõn√≠ na velk√Ω kontext pro GPT-4.1 Nano
        if (approxTokens > 100000) {
            console.log(`üí° GPT-4.1 Nano supports up to ${CONFIG.API.OPENAI.CONTEXT_WINDOW.toLocaleString()} tokens!`);
        }
    } else {
        console.warn('‚ö†Ô∏è No knowledge files were loaded');
    }
}

// Odesl√°n√≠ zpr√°vy
async function sendMessage() {
    const chatInput = document.getElementById('chat-input');
    const sendButton = document.getElementById('send-button');
    const messageText = chatInput.value.trim();
    
    if (!messageText) return;
    
    // Kontrola rate limitingu
    if (CONFIG.RATE_LIMITING.ENABLED && !checkRateLimit()) {
        if (window.uiManager) {
            window.uiManager.addMessage('system', CONFIG.RATE_LIMITING.COOLDOWN_MESSAGE);
        }
        return;
    }
    
    // P≈ôidat u≈æivatelovu zpr√°vu
    if (window.uiManager) {
        window.uiManager.addMessage('user', messageText);
    }
    messages.push({ role: 'user', content: messageText });
    
    // Vyƒçistit input a nastavit loading stav
    chatInput.value = '';
    chatInput.style.height = 'auto'; // Reset v√Ω≈°ky
    chatInput.style.overflowY = 'hidden'; // Reset scrollbaru
    chatInput.disabled = true;
    sendButton.disabled = true;
    sendButton.textContent = CONFIG.MESSAGES.LOADING;
    
    // P≈ôidat loading indik√°tor
    if (window.uiManager) {
        window.uiManager.addMessage('system', CONFIG.MESSAGES.LOADING);
    }
    
    try {
        let response;
        
        // Vol√°n√≠ podle zvolen√©ho re≈æimu - P≈òES PROXY
        if (CONFIG.MODE === "agent") {
            response = await callAgentViaProxy(messageText);
        } else {
            response = await callKnowledgeViaProxy(messages);
        }
        
        // P≈ôidat odpovƒõƒè
        if (window.uiManager) {
            window.uiManager.addMessage('assistant', response);
        }
        messages.push({ role: 'assistant', content: response });
        
    } catch (error) {
        console.error('‚ùå Error:', error);
        let errorMessage = CONFIG.MESSAGES.ERROR;
        
        // Specifick√© chybov√© hl√°≈°ky
        if (error.message.includes('401')) {
            errorMessage = 'Neplatn√Ω API kl√≠ƒç. Zkontrolujte nastaven√≠ v Cloudflare.';
        } else if (error.message.includes('429')) {
            errorMessage = 'P≈ôekroƒçen limit po≈æadavk≈Ø. Zkuste to pozdƒõji.';
        } else if (error.message.includes('Failed to fetch')) {
            errorMessage = 'Chyba p≈ôipojen√≠ k internetu.';
        } else if (error.message.includes('agent') || error.message.includes('Agent')) {
            errorMessage = 'Chyba Agent API. Zkontrolujte AGENT ID v config.js.';
        } else if (error.message.includes('model')) {
            errorMessage = 'Chyba modelu. GPT-4.1 Nano nemus√≠ b√Ωt dostupn√Ω.';
        }
        
        if (window.uiManager) {
            window.uiManager.addMessage('error', errorMessage);
        }
    } finally {
        // Obnovit UI
        chatInput.disabled = false;
        sendButton.disabled = false;
        sendButton.textContent = 'Odeslat';
        chatInput.focus();
    }
}

// Vol√°n√≠ OpenAI Agent API p≈ôes proxy
async function callAgentViaProxy(userMessage) {
    console.log('ü§ñ Using Agent mode via proxy');
    console.log('üîó Proxy URL:', CONFIG.PROXY.URL);
    console.log('üìù Agent ID:', CONFIG.AGENT.AGENT_ID);
    console.log('üß† Model:', CONFIG.AGENT.MODEL || CONFIG.MODEL_INFO.ID);
    console.log('üì§ Message:', userMessage.substring(0, 50) + '...');
    
    // 1. Vytvo≈ôit thread pokud neexistuje
    if (!agentThreadId) {
        console.log('üîÑ Creating new thread...');
        const threadResponse = await fetch(`${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.AGENT}/threads`, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            }
        });
        
        console.log('üì• Thread creation response:', threadResponse.status);
        
        if (!threadResponse.ok) {
            const errorData = await threadResponse.json();
            console.error('‚ùå Thread creation error:', errorData);
            throw new Error(`Agent API error: ${errorData.error || threadResponse.status}`);
        }
        
        const threadData = await threadResponse.json();
        agentThreadId = threadData.id;
        console.log('‚úÖ Created thread:', agentThreadId);
    }
    
    // 2. a 3. P≈ôidat zpr√°vu a spustit agenta PARALELNƒö
    console.log('üì® Adding message and starting run with GPT-4.1 Nano...');
    
    // Paraleln√≠ vol√°n√≠ pro rychlost
    const [messageResponse, runResponse] = await Promise.all([
        // P≈ôidat zpr√°vu
        fetch(`${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.AGENT}/threads/${agentThreadId}/messages`, {
            method: "POST",
            headers: {
                "Content-Type": "application/json"
            },
            body: JSON.stringify({
                role: "user",
                content: userMessage
            })
        }),
        // Poƒçkat 100ms a pak spustit run (OpenAI pot≈ôebuje chv√≠li na zpracov√°n√≠ zpr√°vy)
        new Promise(resolve => setTimeout(resolve, 100)).then(() =>
            fetch(`${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.AGENT}/threads/${agentThreadId}/runs`, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({
                    assistant_id: CONFIG.AGENT.AGENT_ID,
                    model: CONFIG.AGENT.MODEL || "gpt-4.1-nano",  // Explicitnƒõ nastavit model
                    max_completion_tokens: CONFIG.API.OPENAI.MAX_TOKENS || 32768
                })
            })
        )
    ]);
    
    console.log('üì• Message response:', messageResponse.status);
    console.log('üì• Run response:', runResponse.status);
    
    if (!messageResponse.ok) {
        const error = await messageResponse.json();
        console.error('‚ùå Failed to add message:', error);
    }
    
    if (!runResponse.ok) {
        const errorData = await runResponse.json();
        throw new Error(`Assistant run error: ${errorData.error || runResponse.status}`);
    }
    
    console.log('üì• Run response:', runResponse.status);
    if (!runResponse.ok) {
        const errorData = await runResponse.json();
        console.error('‚ùå Run creation failed:', errorData);
        throw new Error(`Agent run error: ${errorData.error || runResponse.status}`);
    }
    
    const runData = await runResponse.json();
    const runId = runData.id;
    console.log('üèÉ Run started with ID:', runId);
    console.log('üß† Using model:', runData.model || 'gpt-4.1-nano');
    
    // 4. ƒåekat na dokonƒçen√≠ - RYCHLEJ≈†√ç POLLING
    let runStatus = "in_progress";
    let attempts = 0;
    const maxAttempts = 60; // 30 sekund (60 * 500ms)
    
    while ((runStatus === "in_progress" || runStatus === "queued") && attempts < maxAttempts) {
        // Rychlej≈°√≠ polling - 500ms m√≠sto 1000ms
        await new Promise(resolve => setTimeout(resolve, 500));
        attempts++;
        
        // Logovat jen ka≈æd√Ω 4. pokus (ka≈æd√© 2 sekundy)
        if (attempts % 4 === 1) {
            console.log(`‚è≥ Checking run status... (${Math.ceil(attempts/2)}s)`);
        }
        
        const statusResponse = await fetch(
            `${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.AGENT}/threads/${agentThreadId}/runs/${runId}`,
            {
                method: "GET",
                headers: {
                    "Content-Type": "application/json"
                }
            }
        );
        
        if (!statusResponse.ok) {
            const error = await statusResponse.json();
            console.error('‚ùå Status check failed:', error);
            break;
        }
        
        const statusData = await statusResponse.json();
        runStatus = statusData.status;
        
        // Pouze logovat zmƒõny stavu
        if (attempts === 1 || statusData.status !== "in_progress") {
            console.log('üìä Run status:', runStatus);
        }
        
        if (runStatus === 'failed' || runStatus === 'cancelled' || runStatus === 'expired') {
            console.error('‚ùå Run failed with status:', runStatus);
            console.error('Details:', statusData);
            throw new Error(`Agent run ${runStatus}`);
        }
    }
    
    if (attempts >= maxAttempts) {
        throw new Error('Agent timeout - took too long to respond');
    }
    
    // 5. Z√≠skat odpovƒõƒè
    console.log('üì© Getting messages...');
    const messagesResponse = await fetch(
        `${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.AGENT}/threads/${agentThreadId}/messages`,
        {
            method: "GET",
            headers: {
                "Content-Type": "application/json"
            }
        }
    );
    
    console.log('üì• Messages response:', messagesResponse.status);
    if (!messagesResponse.ok) {
        const error = await messagesResponse.json();
        console.error('‚ùå Failed to get messages:', error);
        throw new Error('Failed to retrieve agent response');
    }
    
    const messagesData = await messagesResponse.json();
    console.log('üì¨ Retrieved messages count:', messagesData.data.length);
    
    // Naj√≠t posledn√≠ zpr√°vu od agenta
    const agentMessages = messagesData.data.filter(msg => msg.role === 'assistant');
    console.log('ü§ñ Agent messages found:', agentMessages.length);
    
    if (agentMessages.length === 0) {
        console.error('‚ùå No agent response found');
        console.log('All messages:', messagesData.data.map(m => ({role: m.role, content: m.content[0]?.text?.value?.substring(0, 50)})));
        throw new Error('Agent did not respond');
    }
    
    const lastMessage = agentMessages[0]; // Nejnovƒõj≈°√≠ je prvn√≠
    const responseText = lastMessage.content[0].text.value;
    console.log('‚úÖ Agent response received:', responseText.substring(0, 100) + '...');
    console.log('üöÄ GPT-4.1 Nano delivered response successfully!');
    
    return responseText;
}

// Vol√°n√≠ Knowledge API p≈ôes proxy
async function callKnowledgeViaProxy(messageHistory) {
    console.log('üí¨ Using Knowledge mode via proxy');
    console.log('üîó Proxy URL:', CONFIG.PROXY.URL);
    console.log('üß† Model:', CONFIG.API.OPENAI.MODEL);
    console.log('üì§ Sending request to:', `${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.KNOWLEDGE}`);
    
    // Sestavit syst√©mov√Ω prompt s knowledge base
    let systemPrompt = CONFIG.API.OPENAI.SYSTEM_PROMPT;
    if (knowledgeBase) {
        systemPrompt = `${CONFIG.API.OPENAI.SYSTEM_PROMPT}\n\n${knowledgeBase}`;
        console.log('üìö Knowledge base included in prompt');
    }
    
    const requestPayload = {
        model: CONFIG.API.OPENAI.MODEL,
        messages: [
            {
                role: "system",
                content: systemPrompt
            },
            ...messageHistory
        ],
        temperature: CONFIG.API.OPENAI.TEMPERATURE,
        max_tokens: CONFIG.API.OPENAI.MAX_TOKENS
    };
    
    console.log('üìä Request details:');
    console.log('  - Model:', requestPayload.model);
    console.log('  - Messages count:', requestPayload.messages.length);
    console.log('  - Temperature:', requestPayload.temperature);
    console.log('  - Max tokens:', requestPayload.max_tokens);
    console.log('  - Context window:', CONFIG.API.OPENAI.CONTEXT_WINDOW?.toLocaleString() || 'Not specified');
    
    // Vypoƒç√≠tat p≈ôibli≈ænou velikost kontextu
    const contextSize = JSON.stringify(requestPayload.messages).length;
    const approxTokens = Math.ceil(contextSize / 4);
    console.log(`  - Approx. context size: ~${approxTokens} tokens`);
    
    if (CONFIG.API.OPENAI.CONTEXT_WINDOW && approxTokens < CONFIG.API.OPENAI.CONTEXT_WINDOW / 10) {
        console.log(`üí° Using only ~${Math.round(approxTokens / CONFIG.API.OPENAI.CONTEXT_WINDOW * 100)}% of GPT-4.1 Nano's context window`);
    }
    
    const response = await fetch(`${CONFIG.PROXY.URL}${CONFIG.PROXY.ENDPOINTS.KNOWLEDGE}`, {
        method: "POST",
        headers: {
            "Content-Type": "application/json"
        },
        body: JSON.stringify(requestPayload)
    });
    
    console.log('üì• Response status:', response.status);
    
    if (!response.ok) {
        const errorData = await response.json();
        console.error('‚ùå API Error details:', errorData);
        console.error('‚ùå Full error:', JSON.stringify(errorData, null, 2));
        
        // Specifick√© chyby podle odpovƒõdi
        let errorMessage = errorData.error || `Status ${response.status}`;
        if (typeof errorData.error === 'object') {
            errorMessage = errorData.error.message || errorData.error.error || JSON.stringify(errorData.error);
        }
        
        throw new Error(`OpenAI API error: ${errorMessage}`);
    }
    
    const data = await response.json();
    console.log('‚úÖ Response received successfully');
    console.log('üìù Response preview:', data.choices[0].message.content.substring(0, 100) + '...');
    
    // Logovat info o modelu pokud je v odpovƒõdi
    if (data._model_info) {
        console.log('üß† Model info:', data._model_info);
    }
    
    console.log('üöÄ GPT-4.1 Nano delivered response successfully!');
    
    return data.choices[0].message.content;
}

// Rate limiting
function checkRateLimit() {
    if (!CONFIG.RATE_LIMITING.ENABLED) return true;
    
    rateLimitCounter++;
    
    if (!rateLimitTimer) {
        rateLimitTimer = setTimeout(() => {
            rateLimitCounter = 0;
            rateLimitTimer = null;
        }, 60000); // Reset po minutƒõ
    }
    
    return rateLimitCounter <= CONFIG.RATE_LIMITING.MAX_MESSAGES_PER_MINUTE;
}

// Inicializace aplikace
async function initApp() {
    console.log('üöÄ Starting My AI Chat...');
    console.log('üìå App Version:', APP_VERSION);
    console.log('üìå Config Version:', CONFIG.VERSION || 'not set');
    console.log('üìå Last Update:', CONFIG.LAST_UPDATE || 'not set');
    console.log('ü§ñ Mode:', CONFIG.MODE);
    console.log('üß† Model:', CONFIG.MODEL_INFO ? CONFIG.MODEL_INFO.NAME : CONFIG.API.OPENAI.MODEL);
    console.log('üîê Using proxy:', CONFIG.PROXY.URL);
    
    // Zobrazit info o modelu
    if (CONFIG.MODEL_INFO) {
        console.log('');
        console.log('=== GPT-4.1 NANO INFO ===');
        console.log('üìù Description:', CONFIG.MODEL_INFO.DESCRIPTION);
        console.log('üìä Context window:', CONFIG.MODEL_INFO.CONTEXT_WINDOW.toLocaleString(), 'tokens');
        console.log('üì§ Max output:', CONFIG.MODEL_INFO.MAX_OUTPUT.toLocaleString(), 'tokens');
        console.log('üéØ Capabilities:', CONFIG.MODEL_INFO.CAPABILITIES.join(', '));
        console.log('üîß Assistant API:', CONFIG.MODEL_INFO.SUPPORTS_ASSISTANT_API ? 'Supported ‚úÖ' : 'Not supported ‚ùå');
        console.log('========================');
        console.log('');
    }
    
    // Naƒç√≠st knowledge base pouze v knowledge re≈æimu
    if (CONFIG.MODE === "knowledge") {
        await loadKnowledgeBase();
    } else if (CONFIG.MODE === "agent") {
        console.log('ü§ñ Using Agent:', CONFIG.AGENT.AGENT_ID || 'Not configured');
        console.log('üß† Agent Model:', CONFIG.AGENT.MODEL || 'Default');
    }
    
    // OPRAVA: Naƒç√≠st ulo≈æen√© t√©ma, nebo pou≈æ√≠t v√Ωchoz√≠
    if (window.uiManager) {
        const savedTheme = localStorage.getItem('selectedTheme');
        const themeToUse = savedTheme || CONFIG.UI.DEFAULT_THEME;
        console.log('üé® Loading theme:', themeToUse, savedTheme ? '(saved)' : '(default)');
        window.uiManager.setTheme(themeToUse);
    }
    
    console.log('‚úÖ My AI Chat ready with proxy protection');
    console.log('üöÄ Powered by GPT-4.1 Nano - The fastest model with massive context!');
}

// Spu≈°tƒõn√≠ aplikace
window.addEventListener('load', function() {
    console.log('üåü Window loaded, starting app...');
    setTimeout(initApp, 100);
});

// Export pro testov√°n√≠
window.chatSystem = {
    messages: messages,
    sendMessage: sendMessage,
    config: CONFIG,
    clearMessages: () => { 
        messages = []; 
        agentThreadId = null; // Reset thread p≈ôi clear
    },
    mode: CONFIG.MODE,
    modelInfo: CONFIG.MODEL_INFO
};

// Zachov√°n√≠ kompatibility
window.sendMessage = sendMessage;

console.log('üì¶ Main.js loaded successfully');
console.log('üß† Ready to use GPT-4.1 Nano!');
